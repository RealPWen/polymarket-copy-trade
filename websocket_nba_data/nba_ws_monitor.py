#!/usr/bin/env python3
"""
NBA ä¸“é¡¹ WebSocket å®æ—¶ç›‘æ§ä¸»ç¨‹åº

åŠŸèƒ½ï¼š
1. ä» Gamma API / æœ¬åœ° markets.parquet è·å–æ‰€æœ‰ NBA å¸‚åœºçš„ token ID
2. é€šè¿‡ WebSocket è®¢é˜…è¿™äº› token çš„å®æ—¶ä»·æ ¼å˜åŠ¨
3. å°†å®æ—¶æ•°æ®è½ç›˜ä¸º Parquet æ–‡ä»¶ + æ§åˆ¶å°æ‰“å°
"""
import asyncio
import json
import logging
import os
import signal
import sys
import time
from datetime import datetime
from pathlib import Path

import pandas as pd
import requests

# æœ¬é¡¹ç›®æ¨¡å—
from config import (
    DATA_DIR, LOG_DIR, GAMMA_API_URL, MARKETS_FILE, FLUSH_INTERVAL,
    MARKET_FILTER_MODE, EXCLUDED_EVENT_TITLES,
)
from ws_client import PolymarketWSClient

# ============== æ—¥å¿—é…ç½® ==============
log_file = LOG_DIR / f"nba_ws_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(name)s] %(levelname)s: %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler(log_file, encoding="utf-8"),
    ],
)
logger = logging.getLogger("NBA_WS")


# ============== NBA å¸‚åœºå‘ç° ==============

def get_nba_tokens_from_local() -> dict:
    """
    ä»æœ¬åœ° markets.parquet ä¸­æå– NBA å¸‚åœºçš„ token IDs
    è¿”å›: {token_id: {"market_id": ..., "question": ..., "answer": ...}}
    """
    if not MARKETS_FILE.exists():
        logger.warning(f"æœ¬åœ°å¸‚åœºæ–‡ä»¶ä¸å­˜åœ¨: {MARKETS_FILE}")
        return {}

    try:
        df = pd.read_parquet(MARKETS_FILE)
        nba_mask = (
            df["question"].str.contains(r"\bNBA\b", case=False, na=False, regex=True)
            | df["slug"].str.contains(r"\bNBA\b", case=False, na=False, regex=True)
        )
        nba_markets = df[nba_mask]
        logger.info(f"ğŸ€ ä»æœ¬åœ°æ–‡ä»¶å‘ç° {len(nba_markets)} ä¸ª NBA å¸‚åœºï¼ˆæœªè¿‡æ»¤ï¼‰")

        # æ’é™¤å·²å…³é—­/ç»“ç®—çš„å¸‚åœº
        if "closed" in nba_markets.columns:
            open_count_before = len(nba_markets)
            nba_markets = nba_markets[nba_markets["closed"] == False]
            logger.info(f"ğŸ“‚ æ’é™¤å·²å…³é—­å¸‚åœºåå‰©ä½™ {len(nba_markets)} ä¸ªï¼ˆæ’é™¤äº† {open_count_before - len(nba_markets)} ä¸ªï¼‰")

        # æ ¹æ®é…ç½®è¿›è¡Œè¿‡æ»¤
        if MARKET_FILTER_MODE == "all_nba":
            # åŸºäº event_title é»‘åå•æ’é™¤è¯¯åŒ¹é…
            def is_excluded(event_title):
                title_upper = str(event_title).upper()
                return any(ex.upper() in title_upper for ex in EXCLUDED_EVENT_TITLES)
            
            exclude_mask = nba_markets["event_title"].apply(is_excluded)
            nba_markets = nba_markets[~exclude_mask]
            logger.info(
                f"ğŸ¯ all_nba æ¨¡å¼: ä¿ç•™ {len(nba_markets)} ä¸ªå¸‚åœº "
                f"(æ’é™¤äº† {exclude_mask.sum()} ä¸ªè¯¯åŒ¹é…)"
            )
        elif MARKET_FILTER_MODE == "all":
            logger.info(f"ğŸ“¦ æ¨¡å¼=allï¼Œè®¢é˜…å…¨éƒ¨ {len(nba_markets)} ä¸ª NBA å¸‚åœº")

        token_map = {}
        for _, row in nba_markets.iterrows():
            question = row.get("question", "")
            market_id = str(row.get("id", ""))
            event_title = str(row.get("event_title", ""))
            event_id = str(row.get("event_id", ""))
            end_date = str(row.get("end_date", ""))
            
            # token1 å’Œ token2 åˆ†åˆ«å¯¹åº” Yes/No
            for token_col, answer_col in [("token1", "answer1"), ("token2", "answer2")]:
                token_id = str(row.get(token_col, ""))
                answer = str(row.get(answer_col, ""))
                if token_id and token_id != "nan" and token_id != "":
                    token_map[token_id] = {
                        "market_id": market_id,
                        "question": question,
                        "answer": answer,
                        "event_title": event_title,
                        "event_id": event_id,
                        "end_date": end_date,
                    }

        logger.info(f"ğŸ“‹ å…±æå– {len(token_map)} ä¸ª NBA token IDs")
        # æ‰“å°åˆ†ç»„æ‘˜è¦
        event_titles = set(v["event_title"] for v in token_map.values())
        logger.info(f"ğŸ“‚ å…± {len(event_titles)} ä¸ªå¸‚åœºå¤§ç±»")
        return token_map

    except Exception as e:
        logger.error(f"è¯»å–æœ¬åœ°å¸‚åœºæ–‡ä»¶å¤±è´¥: {e}")
        return {}


def get_nba_tokens_from_api() -> dict:
    """
    ä» Gamma API åœ¨çº¿è·å– NBA å¸‚åœºçš„ token IDsï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
    """
    token_map = {}
    offset = 0
    batch_size = 100

    logger.info("ğŸŒ ä» Gamma API è·å– NBA å¸‚åœº...")

    while True:
        try:
            resp = requests.get(
                f"{GAMMA_API_URL}/markets",
                params={
                    "limit": batch_size,
                    "offset": offset,
                    "tag": "nba",  # Gamma API æ”¯æŒ tag è¿‡æ»¤
                    "active": "true",
                    "closed": "false",
                },
                timeout=30,
            )
            if resp.status_code != 200:
                logger.warning(f"API è¿”å› {resp.status_code}ï¼Œåœæ­¢è·å–")
                break

            markets = resp.json()
            if not markets:
                break

            for m in markets:
                question = m.get("question", "")
                market_id = str(m.get("id", ""))
                
                # æ£€æŸ¥æ˜¯å¦çœŸçš„æ˜¯ NBA ç›¸å…³
                if not any(kw in question.upper() for kw in ["NBA", "BASKETBALL"]):
                    if not any(kw in m.get("slug", "").upper() for kw in ["NBA"]):
                        continue

                outcomes = m.get("outcomes", "[]")
                if isinstance(outcomes, str):
                    try:
                        outcomes = json.loads(outcomes)
                    except:
                        outcomes = []

                clob_tokens = m.get("clobTokenIds", "[]")
                if isinstance(clob_tokens, str):
                    try:
                        clob_tokens = json.loads(clob_tokens)
                    except:
                        clob_tokens = []

                for i, token_id in enumerate(clob_tokens):
                    if token_id:
                        token_map[token_id] = {
                            "market_id": market_id,
                            "question": question,
                            "answer": outcomes[i] if i < len(outcomes) else f"outcome_{i}",
                            "event_title": m.get("groupItemTitle", m.get("question", "")),
                            "event_id": str(m.get("id", "")),
                            "end_date": m.get("endDate", ""),
                        }

            if len(markets) < batch_size:
                break
            offset += batch_size
            time.sleep(0.3)  # é¿å… API é™æµ

        except Exception as e:
            logger.error(f"API è¯·æ±‚å‡ºé”™: {e}")
            break

    logger.info(f"ğŸ“‹ ä» API è·å–åˆ° {len(token_map)} ä¸ª NBA token IDs")
    return token_map


# ============== æ•°æ®æ”¶é›†å™¨ ==============

class NBADataCollector:
    """æ”¶é›† WebSocket æ¨é€çš„å®æ—¶æ•°æ®å¹¶è½ç›˜"""

    def __init__(self, token_map: dict):
        self.token_map = token_map
        self.buffer = []  # å†…å­˜ç¼“å†²åŒº
        self.session_ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.output_file = DATA_DIR / f"nba_ws_{self.session_ts}.parquet"
        self.total_events = 0
        self.total_flushed = 0

    def on_message(self, event: dict):
        """
        WebSocket æ¶ˆæ¯å›è°ƒ - å¤„ç†ä¸‰ç§äº‹ä»¶ç±»å‹

        1. book: å®Œæ•´è®¢å•ç°¿å¿«ç…§
           {event_type: "book", asset_id, market, bids, asks, last_trade_price, ...}
        2. price_change: ä»·æ ¼å˜åŠ¨
           {event_type: "price_change", market, price_changes: [{asset_id, price, ...}], ...}
        3. last_trade_price: æœ€æ–°æˆäº¤ä»·
           {event_type: "last_trade_price", asset_id, price, ...}
        """
        event_type = event.get("event_type", "unknown")

        if event_type == "book":
            self._handle_book(event)
        elif event_type == "price_change":
            self._handle_price_change(event)
        elif event_type == "last_trade_price":
            self._handle_last_trade(event)
        else:
            # æœªçŸ¥ç±»å‹ï¼Œè®°å½•ä½†å‡å°‘æ—¥å¿—å™ªå£°
            self._append_record(event_type, event.get("asset_id", ""), 0, event)

        # å®šæœŸè½ç›˜
        if len(self.buffer) >= FLUSH_INTERVAL:
            self.flush()

    def _normalize_record(self, record, original_answer):
        """
        æ•°æ®å½’ä¸€åŒ–ï¼šå¦‚æœåŸå§‹æ˜¯ Noï¼Œåˆ™ 1-Price è½¬æ¢ä¸º Yes è§†è§’
        """
        if str(original_answer).strip().lower() == "no":
            # ä»·æ ¼ç¿»è½¬
            record["price"] = 1.0 - record["price"] if record["price"] > 0 else 0
            
            # ç›˜å£ç¿»è½¬ï¼šNo çš„ Best Bid -> Yes çš„ Best Ask
            # No çš„ Best Ask -> Yes çš„ Best Bid
            orig_bid = record.get("best_bid", 0)
            orig_ask = record.get("best_ask", 0)
            
            record["best_bid"] = 1.0 - orig_ask if orig_ask > 0 else 0
            record["best_ask"] = 1.0 - orig_bid if orig_bid > 0 else 0
            
            # æ ‡è®°å½’ä¸€åŒ–
            record["answer"] = "Yes (Normalized)"
        else:
            record["answer"] = "Yes"
        return record

    def _handle_book(self, event: dict):
        """å¤„ç† book äº‹ä»¶ï¼šæå–æœ€ä¼˜ä¹°å–ä»·å’Œæœ€æ–°æˆäº¤ä»·"""
        asset_id = event.get("asset_id", "")
        market_info = self.token_map.get(asset_id, {})
        original_answer = market_info.get("answer", "Yes")

        # æœ€æ–°æˆäº¤ä»·
        try:
            last_trade = float(event.get("last_trade_price", 0) or 0)
        except (ValueError, TypeError):
            last_trade = 0
        
        # æœ€ä¼˜ä¹°å–ä»·
        bids = event.get("bids", [])
        asks = event.get("asks", [])
        try:
            best_bid = float(bids[0]["price"]) if bids else 0
        except (ValueError, TypeError, KeyError, IndexError):
            best_bid = 0
        try:
            best_ask = float(asks[0]["price"]) if asks else 0
        except (ValueError, TypeError, KeyError, IndexError):
            best_ask = 0

        record = {
            "timestamp": time.time(),
            "datetime": datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f")[:-3],
            "event_type": "book",
            "asset_id": asset_id,
            "market_id": market_info.get("market_id", ""),
            "question": market_info.get("question", "æœªçŸ¥å¸‚åœº"),
            "event_title": market_info.get("event_title", ""),
            "event_id": market_info.get("event_id", ""),
            "price": last_trade,
            "best_bid": best_bid,
            "best_ask": best_ask,
            "bid_depth": len(bids),
            "ask_depth": len(asks),
        }
        
        # å½’ä¸€åŒ–å¤„ç†
        record = self._normalize_record(record, original_answer)
        
        self.buffer.append(record)
        self.total_events += 1

        q_short = record["question"][:40]
        logger.debug(
            f"ğŸ“– ç›˜å£ | {q_short} [å½’ä¸€åŒ–] "
            f"ä¹°={record['best_bid']:.3f} å–={record['best_ask']:.3f} æœ€æ–°æˆäº¤={record['price']:.3f}"
        )

    def _handle_price_change(self, event: dict):
        """å¤„ç† price_change äº‹ä»¶ï¼šåŒ…å« price_changes æ•°ç»„"""
        changes = event.get("price_changes", [])
        for change in changes:
            asset_id = change.get("asset_id", "")
            market_info = self.token_map.get(asset_id, {})
            original_answer = market_info.get("answer", "Yes")
            try:
                price = float(change.get("price", 0) or 0)
            except (ValueError, TypeError):
                price = 0

            record = {
                "timestamp": time.time(),
                "datetime": datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f")[:-3],
                "event_type": "price_change",
                "asset_id": asset_id,
                "market_id": market_info.get("market_id", ""),
                "question": market_info.get("question", "æœªçŸ¥å¸‚åœº"),
                "event_title": market_info.get("event_title", ""),
                "event_id": market_info.get("event_id", ""),
                "price": price,
                "best_bid": 0,
                "best_ask": 0,
                "bid_depth": 0,
                "ask_depth": 0,
            }
            
            record = self._normalize_record(record, original_answer)
            
            self.buffer.append(record)
            self.total_events += 1

            q_short = record["question"][:40]
            logger.debug(
                f"ğŸ“Š æŠ¥ä»· | {q_short} [å½’ä¸€åŒ–] "
                f"ä»·æ ¼={record['price']:.4f}"
            )

    def _handle_last_trade(self, event: dict):
        """å¤„ç† last_trade_price äº‹ä»¶"""
        asset_id = event.get("asset_id", "")
        market_info = self.token_map.get(asset_id, {})
        original_answer = market_info.get("answer", "Yes")
        try:
            price = float(event.get("price", 0) or 0)
        except (ValueError, TypeError):
            price = 0

        record = {
            "timestamp": time.time(),
            "datetime": datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f")[:-3],
            "event_type": "last_trade_price",
            "asset_id": asset_id,
            "market_id": market_info.get("market_id", ""),
            "question": market_info.get("question", "æœªçŸ¥å¸‚åœº"),
            "event_title": market_info.get("event_title", ""),
            "event_id": market_info.get("event_id", ""),
            "price": price,
            "best_bid": 0,
            "best_ask": 0,
            "bid_depth": 0,
            "ask_depth": 0,
        }
        
        record = self._normalize_record(record, original_answer)
        
        self.buffer.append(record)
        self.total_events += 1

        q_short = record["question"][:40]
        logger.info(
            f"ğŸ’¹ æˆäº¤ | {q_short} [å½’ä¸€åŒ–] "
            f"ä»·æ ¼={record['price']:.4f}"
        )


    def _append_record(self, event_type, asset_id, price, event):
        """é€šç”¨è®°å½•è¿½åŠ """
        market_info = self.token_map.get(asset_id, {})
        record = {
            "timestamp": time.time(),
            "datetime": datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f")[:-3],
            "event_type": event_type,
            "asset_id": asset_id,
            "market_id": market_info.get("market_id", ""),
            "question": market_info.get("question", "æœªçŸ¥å¸‚åœº"),
            "event_title": market_info.get("event_title", ""),
            "event_id": market_info.get("event_id", ""),
            "answer": market_info.get("answer", ""),
            "price": float(price),
            "best_bid": 0,
            "best_ask": 0,
            "bid_depth": 0,
            "ask_depth": 0,
        }
        self.buffer.append(record)
        self.total_events += 1

    def flush(self):
        """å°†ç¼“å†²åŒºæ•°æ®å†™å…¥ Parquet æ–‡ä»¶"""
        if not self.buffer:
            return

        try:
            df_new = pd.DataFrame(self.buffer)

            if self.output_file.exists():
                df_old = pd.read_parquet(self.output_file)
                df_combined = pd.concat([df_old, df_new], ignore_index=True)
            else:
                df_combined = df_new

            df_combined.to_parquet(self.output_file, index=False, compression="snappy")
            flushed_count = len(self.buffer)
            self.total_flushed += flushed_count
            self.buffer = []
            logger.info(
                f"ğŸ’¾ å·²è½ç›˜ {flushed_count} æ¡ â†’ {self.output_file.name} "
                f"(ç´¯è®¡ {self.total_flushed} æ¡)"
            )
        except Exception as e:
            logger.error(f"è½ç›˜å¤±è´¥: {e}")

    def final_flush(self):
        """ç¨‹åºé€€å‡ºå‰çš„æœ€ç»ˆè½ç›˜"""
        if self.buffer:
            logger.info(f"ğŸ“¦ æ­£åœ¨æ‰§è¡Œæœ€ç»ˆè½ç›˜ï¼ˆå‰©ä½™ {len(self.buffer)} æ¡ï¼‰...")
            self.flush()
        logger.info(
            f"âœ¨ æœ¬æ¬¡ä¼šè¯å…±æ”¶åˆ° {self.total_events} æ¡äº‹ä»¶ï¼Œ"
            f"è½ç›˜ {self.total_flushed} æ¡"
        )


# ============== ä¸»ç¨‹åº ==============

async def main():
    # 1. è·å– NBA å¸‚åœº token åˆ—è¡¨
    logger.info("=" * 60)
    logger.info("ğŸ€ NBA WebSocket å®æ—¶ç›‘æ§ å¯åŠ¨ä¸­...")
    logger.info("=" * 60)

    token_map = get_nba_tokens_from_local()
    if not token_map:
        logger.info("æœ¬åœ°æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œå°è¯•ä» API è·å–...")
        token_map = get_nba_tokens_from_api()

    if not token_map:
        logger.error("âŒ æ— æ³•è·å–ä»»ä½• NBA å¸‚åœºçš„ token IDï¼Œè¯·æ£€æŸ¥æ•°æ®æº")
        sys.exit(1)

    # æ‰“å°å‘ç°çš„å¸‚åœºæ‘˜è¦
    questions = set(v["question"] for v in token_map.values())
    logger.info(f"\nğŸ“‹ å°†è®¢é˜…ä»¥ä¸‹ {len(questions)} ä¸ª NBA å¸‚åœº:")
    for i, q in enumerate(sorted(questions), 1):
        logger.info(f"   {i}. {q}")
    logger.info("")

    # 2. åˆå§‹åŒ–æ•°æ®æ”¶é›†å™¨
    collector = NBADataCollector(token_map)

    # 3. åˆå§‹åŒ– WebSocket å®¢æˆ·ç«¯
    asset_ids = list(token_map.keys())
    ws_client = PolymarketWSClient(
        asset_ids=asset_ids,
        on_message=collector.on_message,
    )

    # 4. æ³¨å†Œä¿¡å·å¤„ç†ï¼ˆä¼˜é›…é€€å‡ºï¼‰
    loop = asyncio.get_event_loop()

    def _shutdown(sig):
        logger.info(f"ğŸ›‘ æ”¶åˆ°ä¿¡å· {sig.name}ï¼Œæ­£åœ¨ä¼˜é›…é€€å‡º...")
        ws_client.stop()
        collector.final_flush()

    for sig in (signal.SIGINT, signal.SIGTERM):
        loop.add_signal_handler(sig, _shutdown, sig)

    # 5. å¯åŠ¨ WebSocket è¿æ¥
    logger.info(f"ğŸ”Œ å‡†å¤‡è¿æ¥ WebSocketï¼Œè®¢é˜… {len(asset_ids)} ä¸ª token...")
    await ws_client.connect()

    # ç¡®ä¿é€€å‡ºæ—¶è½ç›˜
    collector.final_flush()


if __name__ == "__main__":
    asyncio.run(main())
